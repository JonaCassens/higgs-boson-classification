# XGBoost hyperparameters optimized for Higgs→ττ classification
# Note: objective, eval_metric, num_class, and scale_pos_weight are auto-configured
# by XGBoostClassifier based on number of classes detected during training

learning_rate: 0.03
max_depth: 7
n_estimators: 200
subsample: 0.8
colsample_bytree: 0.8
gamma: 0.1
min_child_weight: 1
reg_alpha: 0.01
reg_lambda: 0.5

# Training settings
early_stopping_rounds: 30
seed: 42
verbosity: 0
n_jobs: -1

# Binary-specific parameters (ignored in multiclass mode)
scale_pos_weight: 3